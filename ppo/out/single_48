episode: 0, total reward: -257.044
episode: 10, total reward: -360.951
episode: 20, total reward: -376.285
episode: 30, total reward: -468.261
episode: 40, total reward: 10.091
episode: 50, total reward: -20.936
episode: 60, total reward: -60.374
episode: 70, total reward: -124.796
episode: 80, total reward: -140.878
episode: 90, total reward: -69.183
episode: 100, total reward: -360.53
episode: 110, total reward: -162.639
episode: 120, total reward: -120.973
episode: 130, total reward: -126.454
episode: 140, total reward: -116.759
episode: 150, total reward: -222.358
episode: 160, total reward: -154.278
episode: 170, total reward: -86.856
episode: 180, total reward: -102.884
episode: 190, total reward: -154.628
episode: 200, total reward: -135.057
episode: 210, total reward: -165.434
episode: 220, total reward: -99.392
episode: 230, total reward: -69.713
episode: 240, total reward: -101.307
episode: 250, total reward: -70.706
episode: 260, total reward: -130.257
episode: 270, total reward: -88.645
episode: 280, total reward: -122.9
episode: 290, total reward: -131.403
episode: 300, total reward: -100.104
episode: 310, total reward: -115.184
episode: 320, total reward: -193.575
episode: 330, total reward: -91.841
episode: 340, total reward: -122.988
episode: 350, total reward: -103.259
episode: 360, total reward: -72.017
episode: 370, total reward: -68.7
episode: 380, total reward: -96.379
episode: 390, total reward: 25.73
episode: 400, total reward: -36.625
episode: 410, total reward: -91.52
episode: 420, total reward: -112.272
episode: 430, total reward: -25.942
episode: 440, total reward: -144.352
episode: 450, total reward: -162.794
episode: 460, total reward: -129.208
episode: 470, total reward: -281.355
episode: 480, total reward: -217.94
episode: 490, total reward: -280.993
episode: 500, total reward: 7.275
episode: 510, total reward: -55.469
episode: 520, total reward: -196.767
episode: 530, total reward: -226.359
episode: 540, total reward: 3.791
episode: 550, total reward: -120.365
episode: 570, total reward: -13.528
episode: 580, total reward: -28.581
episode: 590, total reward: 3.105
episode: 600, total reward: 1.052
episode: 610, total reward: -152.759
episode: 620, total reward: -64.318
episode: 630, total reward: -14.27
episode: 640, total reward: 7.152
episode: 700, total reward: -45.662
episode: 710, total reward: 9.665
episode: 720, total reward: 42.757
episode: 730, total reward: 48.844
episode: 740, total reward: 13.904
episode: 750, total reward: 38.074
episode: 910, total reward: -5.428
episode: 920, total reward: -5.264
episode: 930, total reward: -2.613
episode: 1210, total reward: -49.753
episode: 1220, total reward: -80.346
episode: 1480, total reward: -4.757
episode: 1490, total reward: 10.454
episode: 1570, total reward: 10.926
episode: 1660, total reward: 45.83
episode: 1670, total reward: -40.749
episode: 1710, total reward: 19.679
episode: 1750, total reward: 58.569
episode: 1780, total reward: 34.704
episode: 1790, total reward: 7.797
episode: 1810, total reward: 17.121
episode: 1820, total reward: 251.715
episode: 1830, total reward: -18.342
episode: 1870, total reward: 222.779
episode: 1890, total reward: 229.995
episode: 1910, total reward: 31.966
episode: 1940, total reward: -9.017
episode: 1950, total reward: 64.098
episode: 1980, total reward: 5.847
episode: 2020, total reward: 12.1
episode: 2070, total reward: -8.806
episode: 2100, total reward: 48.17
episode: 2130, total reward: -28.922
episode: 2140, total reward: 15.175
episode: 2160, total reward: 6.988
episode: 2170, total reward: -19.626
episode: 2180, total reward: 16.247
episode: 2200, total reward: 247.103
episode: 2250, total reward: 15.366
episode: 2270, total reward: 49.223
episode: 2330, total reward: 48.271
episode: 2350, total reward: 2.268
episode: 2360, total reward: 226.163
episode: 2370, total reward: 7.138
episode: 2390, total reward: -53.463
episode: 2400, total reward: 213.205
episode: 2410, total reward: -56.138
episode: 2420, total reward: 225.957
episode: 2500, total reward: 16.31
episode: 2800, total reward: 74.057
episode: 2860, total reward: -2.326
episode: 2910, total reward: -0.43
episode: 2970, total reward: -3.775
predict_state.0.weight Parameter containing:
tensor([[-0.1893,  0.0092,  0.0625,  ..., -0.0049,  0.0083, -0.0474],
        [ 0.1121,  0.0338, -0.0061,  ..., -0.0347, -0.0092, -0.0274],
        [ 0.1246,  0.1505, -0.2296,  ..., -0.0502, -0.0332, -0.0105],
        ...,
        [-0.0081,  0.0167, -0.1650,  ...,  0.0950, -0.0099,  0.0727],
        [-0.0155,  0.0022,  0.0523,  ...,  0.0430, -0.0684,  0.0802],
        [ 0.0150, -0.0661,  0.1161,  ..., -0.0802, -0.0604,  0.0801]],
       requires_grad=True)
predict_state.0.bias Parameter containing:
tensor([-4.4596e-02,  1.3250e-04, -3.5961e-02, -1.5325e-02,  2.1577e-02,
         1.0184e-02, -1.2169e-01, -2.6906e-03,  1.1302e-01, -4.1310e-02,
        -4.3137e-02,  2.0280e-02, -1.1775e-02,  1.2744e-01,  1.2844e-02,
         4.9600e-02, -2.5249e-02,  8.8790e-02,  4.5790e-04, -6.2585e-02,
        -8.5139e-02,  4.3045e-02,  1.0162e-01,  3.6487e-02,  8.7880e-02,
         1.3337e-01, -7.7558e-02, -9.2630e-02,  1.2776e-01, -6.4887e-02,
         6.9783e-02,  8.8582e-02,  8.8887e-02, -4.6120e-02, -7.9352e-02,
        -1.4459e-02, -6.4002e-03,  6.8730e-02, -4.2523e-02,  1.6722e-02,
         5.6664e-02, -4.7889e-02, -5.7404e-02,  1.3648e-01,  3.9403e-02,
         2.4098e-02,  4.4923e-02, -4.6038e-02,  5.2970e-03,  3.8594e-02,
        -8.9737e-02, -2.6972e-02, -3.9507e-02,  1.6571e-01, -4.2434e-02,
        -6.0466e-02, -6.1456e-02, -3.3864e-02,  4.8362e-02,  2.3340e-02,
        -4.2740e-02, -5.4694e-02,  1.1608e-01, -3.0817e-02],
       requires_grad=True)
predict_state.2.weight Parameter containing:
tensor([[-0.0740, -0.0334, -0.0230,  ..., -0.0379,  0.0805, -0.0049],
        [-0.0497,  0.0065,  0.1203,  ...,  0.0715, -0.1309,  0.1493],
        [ 0.1086, -0.0983,  0.0593,  ...,  0.0442,  0.0105, -0.0465],
        ...,
        [-0.0900, -0.0675,  0.0670,  ...,  0.0728,  0.0247,  0.0086],
        [-0.0465, -0.1143, -0.0286,  ..., -0.1112,  0.0143,  0.0343],
        [ 0.0934,  0.0602,  0.0883,  ...,  0.0666,  0.0247,  0.0548]],
       requires_grad=True)
predict_state.2.bias Parameter containing:
tensor([-0.0010,  0.1162,  0.1119,  0.0712,  0.0165, -0.0346,  0.0917,  0.0443,
        -0.0763,  0.0872,  0.0541,  0.1308, -0.0757,  0.0853,  0.0990, -0.0332,
         0.0481,  0.0016, -0.0387, -0.0670, -0.0919,  0.0558,  0.1365,  0.1405,
        -0.0745,  0.1016,  0.0303, -0.0139, -0.0551,  0.0979,  0.1114,  0.1394,
         0.1017,  0.0062, -0.0151, -0.0511, -0.0481,  0.0970, -0.0264,  0.0165,
         0.0414, -0.0214, -0.0330, -0.0617, -0.0267, -0.0679, -0.0341,  0.1165,
        -0.0639, -0.0068, -0.0092, -0.0054,  0.0204, -0.0142, -0.0942,  0.1137,
        -0.1052,  0.0101,  0.0043, -0.0838,  0.0009,  0.0057,  0.0306,  0.0153],
       requires_grad=True)
predict_state.4.weight Parameter containing:
tensor([[-0.1023, -0.2586,  0.0608,  ..., -0.0606, -0.1994, -0.3054],
        [-0.0054, -0.0590,  0.0483,  ..., -0.0868, -0.0241, -0.0833],
        [-0.0900, -0.1875,  0.0635,  ..., -0.0051, -0.2274, -0.2291],
        ...,
        [-0.0991,  0.0968,  0.1422,  ..., -0.0656, -0.1440, -0.0253],
        [ 0.0929,  0.1117,  0.0449,  ...,  0.1469,  0.1492,  0.0519],
        [-0.0904, -0.0683, -0.0458,  ..., -0.0981, -0.0279, -0.1796]],
       requires_grad=True)
predict_state.4.bias Parameter containing:
tensor([ 0.0275, -0.0308, -0.1078, -0.0293,  0.0070, -0.0578,  0.0110,  0.0975,
         0.0070,  0.0293,  0.0179, -0.0512,  0.0619, -0.0069, -0.0222,  0.0693,
        -0.0086, -0.0607,  0.0681,  0.0477,  0.0310,  0.0544,  0.0033,  0.0472,
         0.0368,  0.0205, -0.0498, -0.0163, -0.0247, -0.0529,  0.0750,  0.0623,
        -0.0322, -0.0890,  0.0525,  0.1143, -0.0498, -0.0036, -0.0195, -0.0397,
        -0.0792, -0.0135,  0.0318,  0.0775,  0.1026,  0.0062,  0.0817,  0.0180],
       requires_grad=True)
predict_reward.0.weight Parameter containing:
tensor([[ 0.0583, -0.0347, -0.0929,  ...,  0.1316,  0.0537, -0.0188],
        [ 0.0776, -0.0835,  0.1029,  ...,  0.1237, -0.4056,  0.0867],
        [ 0.1325, -0.0316,  0.1248,  ..., -0.0964,  0.1281, -0.0750],
        ...,
        [ 0.0983,  0.0579,  0.0326,  ...,  0.0773, -0.1639,  0.2975],
        [-0.0660, -0.0051,  0.0137,  ...,  0.0953, -0.4409,  0.2713],
        [-0.0079, -0.0625,  0.0592,  ...,  0.0038, -0.3025,  0.2884]],
       requires_grad=True)
predict_reward.0.bias Parameter containing:
tensor([ 0.0806,  0.0466, -0.0015, -0.0233, -0.0169, -0.0051,  0.0647, -0.0434,
         0.0083,  0.1057, -0.0987, -0.0591,  0.0937,  0.0250,  0.0526,  0.0720,
         0.1567, -0.1205,  0.0706, -0.1204, -0.1161, -0.0698, -0.0818, -0.1514,
        -0.0685,  0.0564,  0.0662,  0.0292, -0.0624,  0.0015, -0.0530,  0.0476,
        -0.0912, -0.0035,  0.0050,  0.0677, -0.1144, -0.0366, -0.0539, -0.0669,
        -0.0598,  0.0633, -0.0967,  0.0493,  0.0645, -0.0401, -0.1421,  0.0702,
        -0.0602, -0.1409, -0.0121, -0.1208,  0.0882,  0.0360,  0.0349,  0.1360,
        -0.1079, -0.1295, -0.0240,  0.1134,  0.0958,  0.0348,  0.1113,  0.0923],
       requires_grad=True)
predict_reward.2.weight Parameter containing:
tensor([[ 0.0907, -0.1424,  0.0151,  ..., -0.1003, -0.2095, -0.0179],
        [ 0.0475,  0.0747, -0.0825,  ...,  0.0489,  0.1234, -0.0324],
        [-0.0949, -0.0475, -0.0468,  ...,  0.0261, -0.0209, -0.0862],
        ...,
        [ 0.0617, -0.0005,  0.0497,  ..., -0.0371, -0.0301,  0.1506],
        [-0.0605,  0.1743,  0.0167,  ..., -0.0373,  0.1760,  0.0744],
        [-0.0150, -0.0913,  0.0344,  ...,  0.0154, -0.0476, -0.1254]],
       requires_grad=True)
predict_reward.2.bias Parameter containing:
tensor([ 0.0225, -0.0003, -0.1146, -0.0984,  0.0694,  0.0102,  0.0362,  0.0727,
        -0.0201,  0.0494,  0.1144, -0.0785, -0.0600,  0.0669,  0.0541, -0.0864,
        -0.0387, -0.0031,  0.1320, -0.0386,  0.0764, -0.0921,  0.0442, -0.0745,
        -0.0109,  0.0999, -0.0285, -0.0464, -0.1339,  0.0012, -0.0729, -0.0578,
         0.1301, -0.0597,  0.0255,  0.0106, -0.0735,  0.0759,  0.0480, -0.0983,
         0.0137, -0.0050,  0.0029,  0.0053, -0.0446,  0.0927, -0.0645, -0.1352,
         0.0635, -0.0612, -0.0248, -0.0076, -0.0286,  0.0626,  0.0559,  0.0566,
        -0.0212, -0.0164,  0.0988,  0.0948,  0.1091,  0.1294,  0.0356, -0.1259],
       requires_grad=True)
predict_reward.4.weight Parameter containing:
tensor([[ 0.1753, -0.1057,  0.1238,  0.1391,  0.0957,  0.1653, -0.1260,  0.1892,
          0.1003,  0.1334, -0.1095,  0.1564, -0.0621,  0.1332,  0.1633, -0.2030,
          0.1525,  0.2321, -0.0542, -0.1329,  0.1167,  0.1077, -0.1379,  0.2022,
          0.2534, -0.1496,  0.1770, -0.1423,  0.0902,  0.1420, -0.1513,  0.1613,
         -0.1073, -0.1234,  0.2254,  0.1904, -0.1295, -0.1494, -0.1359,  0.1822,
         -0.1928, -0.0921,  0.2210, -0.1166,  0.0833,  0.1833,  0.1241,  0.1318,
         -0.1926,  0.0939,  0.2109, -0.1307, -0.0775, -0.1699, -0.1226, -0.0091,
         -0.2005,  0.1015, -0.0602, -0.0885, -0.1328, -0.0720, -0.1259,  0.1740]],
       requires_grad=True)
predict_reward.4.bias Parameter containing:
tensor([-0.1290], requires_grad=True)
mean: -48.501888710281314 std 125.48598646805438
