load from  models/LunarLander-v2_vpg_n3000_f16_single_16
predict_state.0.weight Parameter containing:
tensor([[ 0.0837,  0.0339, -0.0659,  ...,  0.0683,  0.1620, -0.0221],
        [-0.0940,  0.0856, -0.2786,  ...,  0.1549, -0.0024, -0.3960],
        [-0.0445,  0.1011,  0.2671,  ..., -0.0385,  0.1122,  0.1106],
        ...,
        [-0.0106, -0.1861, -0.0213,  ...,  0.2195, -0.1543, -0.0818],
        [ 0.1936,  0.1664, -0.1136,  ..., -0.1282,  0.0357,  0.0061],
        [-0.0975,  0.1764,  0.1055,  ...,  0.0177,  0.0289, -0.0619]],
       device='cuda:0', requires_grad=True)
predict_state.0.bias Parameter containing:
tensor([ 0.0080, -0.2957, -0.1609,  0.1552, -0.1897, -0.0232,  0.0671, -0.0175,
        -0.1579, -0.0719,  0.0272,  0.0590,  0.0328, -0.1598,  0.0366, -0.1148,
        -0.0537,  0.0443,  0.0529,  0.1070,  0.0954, -0.0979,  0.1759,  0.1475,
        -0.1139, -0.0071,  0.1481,  0.1530, -0.2237, -0.0635,  0.0611,  0.1564,
         0.1345,  0.0696, -0.0014,  0.0414,  0.0393,  0.2462,  0.0164, -0.1652,
         0.0396,  0.1435,  0.0426,  0.0044, -0.0433, -0.0953, -0.0633,  0.1355,
        -0.1948,  0.0289, -0.0542,  0.0952,  0.0264,  0.1794,  0.1870,  0.0412,
         0.1684,  0.1332,  0.1238,  0.0480,  0.0951,  0.2108, -0.1949,  0.0030],
       device='cuda:0', requires_grad=True)
predict_state.2.weight Parameter containing:
tensor([[ 0.1210, -0.1961,  0.0561,  ...,  0.0607,  0.2567,  0.1383],
        [ 0.0703,  0.0700,  0.0982,  ...,  0.0273, -0.0146,  0.2100],
        [ 0.0692, -0.0927, -0.0713,  ...,  0.0430, -0.0065, -0.0246],
        ...,
        [ 0.1496,  0.1798,  0.0996,  ..., -0.0144, -0.1990,  0.0338],
        [-0.1007,  0.1950, -0.0413,  ..., -0.0212,  0.0543,  0.0266],
        [-0.0443, -0.1351, -0.0214,  ...,  0.0945,  0.0438,  0.1047]],
       device='cuda:0', requires_grad=True)
predict_state.2.bias Parameter containing:
tensor([-0.0731, -0.1294,  0.1091, -0.0933, -0.0805, -0.0362,  0.0378, -0.0416,
        -0.0193,  0.0667,  0.0918,  0.0845, -0.0326, -0.0244, -0.0579,  0.0286,
         0.0660,  0.0367,  0.0798,  0.0102,  0.0694,  0.0027,  0.0977,  0.0599,
         0.1088,  0.0224, -0.0899, -0.0234,  0.0851, -0.0846,  0.1091, -0.0855,
        -0.0087,  0.0478, -0.0690,  0.0265,  0.0538,  0.1071,  0.0258,  0.0350,
        -0.0233,  0.0642,  0.0537,  0.0853, -0.0016, -0.0673, -0.0792,  0.0742,
        -0.0702, -0.1128,  0.1223,  0.0612,  0.1097,  0.0036, -0.0186, -0.0876,
         0.0399,  0.0526,  0.0393,  0.1056, -0.0854,  0.1111,  0.0933,  0.0871],
       device='cuda:0', requires_grad=True)
predict_state.4.weight Parameter containing:
tensor([[-0.1889, -0.0202,  0.0294,  ...,  0.0255,  0.2579,  0.0122],
        [-0.0565,  0.1405, -0.0317,  ...,  0.2462,  0.0493, -0.3043],
        [-0.0331,  0.1362,  0.0048,  ...,  0.1694,  0.2933, -0.0749],
        ...,
        [ 0.2596, -0.0013, -0.1132,  ..., -0.1064, -0.1021, -0.0494],
        [-0.2916,  0.1106,  0.0284,  ...,  0.2876,  0.1615, -0.2775],
        [ 0.2552, -0.1577,  0.0930,  ..., -0.0285, -0.2922, -0.0356]],
       device='cuda:0', requires_grad=True)
predict_state.4.bias Parameter containing:
tensor([ 0.0509, -0.0365,  0.1051,  0.0231, -0.1117,  0.1001,  0.0169,  0.0567,
        -0.0615, -0.0309,  0.1045,  0.0738, -0.0267,  0.0085,  0.0594, -0.0988],
       device='cuda:0', requires_grad=True)
predict_reward.0.weight Parameter containing:
tensor([[ 0.0981,  0.0904,  0.1695,  ...,  0.0397,  0.0653,  0.0296],
        [ 0.3399, -0.0572,  0.2688,  ..., -0.0290, -0.1406,  0.1829],
        [ 0.0216,  0.0566, -0.1793,  ..., -0.0414,  0.1633,  0.1022],
        ...,
        [-0.0707, -0.1225,  0.1844,  ...,  0.1269,  0.0030,  0.2382],
        [-0.0614, -0.0599,  0.0427,  ...,  0.1384,  0.0629,  0.0175],
        [ 0.1224,  0.1871,  0.2072,  ...,  0.0039, -0.2088,  0.0193]],
       device='cuda:0', requires_grad=True)
predict_reward.0.bias Parameter containing:
tensor([-0.0243,  0.1298, -0.2345,  0.0297,  0.0570,  0.1353,  0.0357, -0.1581,
        -0.2047, -0.1751, -0.1258, -0.1492,  0.1966, -0.1401, -0.1424,  0.1452,
        -0.0428, -0.0265, -0.0751, -0.0207,  0.0214, -0.0541,  0.0376,  0.1757,
        -0.0749,  0.0301,  0.1644, -0.1580, -0.1230,  0.1029,  0.1647, -0.1095,
        -0.0192,  0.0228,  0.1501,  0.1570,  0.2532,  0.1129,  0.1276, -0.0833,
         0.2083, -0.0446,  0.1626,  0.0400,  0.1954, -0.1349, -0.1300,  0.1975,
         0.1167, -0.2050, -0.0386, -0.0319, -0.1121,  0.2069, -0.0708,  0.0703,
        -0.0271,  0.1207, -0.0662, -0.1261,  0.0769,  0.2092,  0.0101,  0.2022],
       device='cuda:0', requires_grad=True)
predict_reward.2.weight Parameter containing:
tensor([[-0.0196, -0.0201, -0.0833,  ..., -0.0046,  0.0999,  0.1278],
        [ 0.0621,  0.0359, -0.0693,  ...,  0.0871, -0.0040,  0.1342],
        [ 0.0430,  0.2113, -0.0692,  ..., -0.0546,  0.1193,  0.0313],
        ...,
        [ 0.0950,  0.1131,  0.0360,  ...,  0.1526,  0.0937,  0.1593],
        [-0.0745,  0.0411, -0.0865,  ...,  0.0865,  0.0299,  0.1118],
        [-0.0355,  0.1539, -0.1625,  ..., -0.0294,  0.0842,  0.0258]],
       device='cuda:0', requires_grad=True)
predict_reward.2.bias Parameter containing:
tensor([ 0.0529,  0.1288,  0.0907,  0.0858, -0.0691,  0.1107,  0.1180,  0.1497,
        -0.1218,  0.1258, -0.0650,  0.0416,  0.0093, -0.1418,  0.0235,  0.0183,
        -0.0764, -0.1308, -0.0635, -0.1132, -0.1203,  0.0256,  0.0779, -0.1442,
        -0.1574, -0.0380, -0.0510,  0.0146, -0.0367, -0.0371,  0.1428, -0.0833,
         0.0907,  0.0025,  0.0415,  0.1210,  0.0609, -0.0520, -0.0278,  0.0353,
        -0.1072,  0.0677,  0.1448,  0.0290, -0.0585, -0.0590,  0.0226,  0.0072,
         0.0860,  0.0354, -0.0466,  0.1549, -0.0086, -0.0450,  0.1599,  0.0224,
        -0.0691,  0.1513, -0.0597, -0.0217, -0.0598, -0.0709,  0.1173,  0.0717],
       device='cuda:0', requires_grad=True)
predict_reward.4.weight Parameter containing:
tensor([[-0.0739, -0.2671, -0.3178,  0.1363, -0.1872, -0.1357, -0.2567, -0.1863,
          0.1727, -0.2853,  0.2359, -0.2859,  0.1870,  0.2436,  0.1758, -0.2629,
          0.3553,  0.2443,  0.1531,  0.2070,  0.3603,  0.2914, -0.1686,  0.2786,
          0.2128,  0.1767,  0.2672,  0.1767, -0.1818, -0.1285, -0.1955,  0.2347,
         -0.1731,  0.2369,  0.2888, -0.2691, -0.0323,  0.1945, -0.0090,  0.3035,
          0.2468,  0.2201, -0.2040, -0.3645,  0.3076, -0.3892, -0.2983,  0.3425,
         -0.2667,  0.1622, -0.2891, -0.1982, -0.3726,  0.0451, -0.2737,  0.1253,
         -0.1294, -0.0991,  0.1598,  0.2450, -0.1782, -0.2423, -0.2327, -0.2463]],
       device='cuda:0', requires_grad=True)
predict_reward.4.bias Parameter containing:
tensor([-0.0963], device='cuda:0', requires_grad=True)
episode: 0, total reward: -78.12
episode: 10, total reward: -88.88
episode: 20, total reward: -298.597
episode: 30, total reward: -126.565
episode: 40, total reward: -237.869
episode: 50, total reward: -106.635
episode: 60, total reward: -124.045
episode: 70, total reward: -343.617
episode: 80, total reward: -92.831
episode: 90, total reward: -152.628
episode: 100, total reward: -114.759
episode: 110, total reward: -118.603
episode: 120, total reward: -120.743
episode: 130, total reward: -122.95
episode: 140, total reward: -95.929
episode: 150, total reward: -135.362
episode: 160, total reward: -121.126
episode: 170, total reward: -128.994
episode: 180, total reward: -93.54
episode: 190, total reward: -107.989
episode: 200, total reward: -159.951
episode: 210, total reward: -114.335
episode: 220, total reward: -132.95
episode: 230, total reward: -27.966
episode: 240, total reward: -159.108
episode: 250, total reward: -134.571
episode: 260, total reward: -102.878
episode: 270, total reward: -99.147
episode: 280, total reward: -97.506
episode: 290, total reward: -166.104
episode: 300, total reward: -144.365
episode: 310, total reward: -129.064
episode: 320, total reward: -143.593
episode: 330, total reward: -128.123
episode: 340, total reward: -123.375
episode: 350, total reward: -315.674
episode: 360, total reward: -125.714
episode: 370, total reward: -88.078
episode: 380, total reward: -375.238
episode: 390, total reward: -61.341
episode: 400, total reward: -105.373
episode: 410, total reward: -96.706
episode: 420, total reward: -135.718
episode: 430, total reward: -124.912
episode: 440, total reward: -191.734
episode: 450, total reward: -131.014
episode: 460, total reward: -83.315
episode: 470, total reward: -68.653
episode: 480, total reward: -89.864
episode: 490, total reward: -117.499
episode: 500, total reward: -134.567
episode: 510, total reward: -126.211
episode: 520, total reward: -98.33
episode: 530, total reward: -293.822
episode: 540, total reward: -86.129
episode: 550, total reward: -96.326
episode: 560, total reward: -140.256
episode: 570, total reward: -102.531
episode: 580, total reward: -130.124
episode: 590, total reward: -73.93
episode: 600, total reward: -118.299
episode: 610, total reward: -128.87
episode: 620, total reward: -69.901
episode: 630, total reward: -96.501
episode: 640, total reward: -198.618
episode: 650, total reward: -106.782
episode: 660, total reward: -95.413
episode: 670, total reward: -56.177
episode: 680, total reward: -83.231
episode: 690, total reward: -99.579
episode: 700, total reward: -93.325
episode: 710, total reward: -96.659
episode: 720, total reward: -74.664
episode: 730, total reward: -78.787
episode: 740, total reward: -102.825
episode: 750, total reward: -239.605
episode: 760, total reward: -80.186
episode: 770, total reward: -143.467
episode: 780, total reward: -166.938
episode: 790, total reward: -67.083
episode: 800, total reward: -98.174
episode: 810, total reward: -64.728
episode: 820, total reward: -89.407
episode: 830, total reward: -95.084
episode: 840, total reward: -65.116
episode: 850, total reward: -78.011
episode: 860, total reward: -66.444
episode: 870, total reward: -78.383
episode: 880, total reward: -63.605
episode: 890, total reward: -101.241
episode: 900, total reward: -71.005
episode: 910, total reward: -27.804
episode: 920, total reward: -90.646
episode: 930, total reward: 6.55
episode: 940, total reward: -54.504
episode: 950, total reward: -22.303
episode: 960, total reward: -75.145
episode: 970, total reward: 7.325
episode: 980, total reward: -32.334
episode: 990, total reward: -72.273
episode: 1000, total reward: -22.273
episode: 1010, total reward: -87.437
episode: 1020, total reward: -11.16
episode: 1030, total reward: -21.819
episode: 1040, total reward: -38.189
episode: 1050, total reward: -21.08
episode: 1060, total reward: -31.874
episode: 1070, total reward: -52.789
episode: 1080, total reward: -32.868
episode: 1090, total reward: -55.565
episode: 1100, total reward: -46.88
episode: 1140, total reward: -2.436
episode: 1160, total reward: 7.14
episode: 1180, total reward: -7.82
episode: 1210, total reward: 17.324
episode: 1230, total reward: -31.255
episode: 1250, total reward: 3.654
episode: 1310, total reward: -146.889
episode: 1320, total reward: 37.545
episode: 1330, total reward: -32.029
episode: 1340, total reward: -29.197
episode: 1350, total reward: 20.797
episode: 1360, total reward: -34.146
episode: 1400, total reward: 39.46
episode: 1430, total reward: 13.126
episode: 1460, total reward: 26.676
episode: 1470, total reward: 36.5
episode: 1480, total reward: -9.0
episode: 1490, total reward: -16.852
episode: 1500, total reward: -65.385
episode: 1520, total reward: -6.8
episode: 1580, total reward: -28.039
episode: 1600, total reward: 23.046
episode: 1640, total reward: -1.984
episode: 1790, total reward: 38.7
episode: 1810, total reward: 11.702
episode: 1840, total reward: -9.777
episode: 1850, total reward: -97.381
episode: 1870, total reward: -11.576
episode: 1880, total reward: -1.753
episode: 1890, total reward: -245.791
episode: 1910, total reward: -3.453
episode: 1980, total reward: 42.031
episode: 2020, total reward: 26.979
episode: 2060, total reward: -12.898
episode: 2440, total reward: 23.492
episode: 2450, total reward: -41.301
episode: 2490, total reward: -19.71
episode: 2510, total reward: 9.458
episode: 2520, total reward: 20.124
episode: 2530, total reward: 32.703
episode: 2550, total reward: -3.634
episode: 2640, total reward: 41.034
episode: 2680, total reward: -12.928
predict_state.0.weight Parameter containing:
tensor([[ 0.0837,  0.0339, -0.0659,  ...,  0.0683,  0.1620, -0.0221],
        [-0.0940,  0.0856, -0.2786,  ...,  0.1549, -0.0024, -0.3960],
        [-0.0445,  0.1011,  0.2671,  ..., -0.0385,  0.1122,  0.1106],
        ...,
        [-0.0106, -0.1861, -0.0213,  ...,  0.2195, -0.1543, -0.0818],
        [ 0.1936,  0.1664, -0.1136,  ..., -0.1282,  0.0357,  0.0061],
        [-0.0975,  0.1764,  0.1055,  ...,  0.0177,  0.0289, -0.0619]],
       device='cuda:0', requires_grad=True)
predict_state.0.bias Parameter containing:
tensor([ 0.0080, -0.2957, -0.1609,  0.1552, -0.1897, -0.0232,  0.0671, -0.0175,
        -0.1579, -0.0719,  0.0272,  0.0590,  0.0328, -0.1598,  0.0366, -0.1148,
        -0.0537,  0.0443,  0.0529,  0.1070,  0.0954, -0.0979,  0.1759,  0.1475,
        -0.1139, -0.0071,  0.1481,  0.1530, -0.2237, -0.0635,  0.0611,  0.1564,
         0.1345,  0.0696, -0.0014,  0.0414,  0.0393,  0.2462,  0.0164, -0.1652,
         0.0396,  0.1435,  0.0426,  0.0044, -0.0433, -0.0953, -0.0633,  0.1355,
        -0.1948,  0.0289, -0.0542,  0.0952,  0.0264,  0.1794,  0.1870,  0.0412,
         0.1684,  0.1332,  0.1238,  0.0480,  0.0951,  0.2108, -0.1949,  0.0030],
       device='cuda:0', requires_grad=True)
predict_state.2.weight Parameter containing:
tensor([[ 0.1210, -0.1961,  0.0561,  ...,  0.0607,  0.2567,  0.1383],
        [ 0.0703,  0.0700,  0.0982,  ...,  0.0273, -0.0146,  0.2100],
        [ 0.0692, -0.0927, -0.0713,  ...,  0.0430, -0.0065, -0.0246],
        ...,
        [ 0.1496,  0.1798,  0.0996,  ..., -0.0144, -0.1990,  0.0338],
        [-0.1007,  0.1950, -0.0413,  ..., -0.0212,  0.0543,  0.0266],
        [-0.0443, -0.1351, -0.0214,  ...,  0.0945,  0.0438,  0.1047]],
       device='cuda:0', requires_grad=True)
predict_state.2.bias Parameter containing:
tensor([-0.0731, -0.1294,  0.1091, -0.0933, -0.0805, -0.0362,  0.0378, -0.0416,
        -0.0193,  0.0667,  0.0918,  0.0845, -0.0326, -0.0244, -0.0579,  0.0286,
         0.0660,  0.0367,  0.0798,  0.0102,  0.0694,  0.0027,  0.0977,  0.0599,
         0.1088,  0.0224, -0.0899, -0.0234,  0.0851, -0.0846,  0.1091, -0.0855,
        -0.0087,  0.0478, -0.0690,  0.0265,  0.0538,  0.1071,  0.0258,  0.0350,
        -0.0233,  0.0642,  0.0537,  0.0853, -0.0016, -0.0673, -0.0792,  0.0742,
        -0.0702, -0.1128,  0.1223,  0.0612,  0.1097,  0.0036, -0.0186, -0.0876,
         0.0399,  0.0526,  0.0393,  0.1056, -0.0854,  0.1111,  0.0933,  0.0871],
       device='cuda:0', requires_grad=True)
predict_state.4.weight Parameter containing:
tensor([[-0.1889, -0.0202,  0.0294,  ...,  0.0255,  0.2579,  0.0122],
        [-0.0565,  0.1405, -0.0317,  ...,  0.2462,  0.0493, -0.3043],
        [-0.0331,  0.1362,  0.0048,  ...,  0.1694,  0.2933, -0.0749],
        ...,
        [ 0.2596, -0.0013, -0.1132,  ..., -0.1064, -0.1021, -0.0494],
        [-0.2916,  0.1106,  0.0284,  ...,  0.2876,  0.1615, -0.2775],
        [ 0.2552, -0.1577,  0.0930,  ..., -0.0285, -0.2922, -0.0356]],
       device='cuda:0', requires_grad=True)
predict_state.4.bias Parameter containing:
tensor([ 0.0509, -0.0365,  0.1051,  0.0231, -0.1117,  0.1001,  0.0169,  0.0567,
        -0.0615, -0.0309,  0.1045,  0.0738, -0.0267,  0.0085,  0.0594, -0.0988],
       device='cuda:0', requires_grad=True)
predict_reward.0.weight Parameter containing:
tensor([[ 0.0981,  0.0904,  0.1695,  ...,  0.0397,  0.0653,  0.0296],
        [ 0.3399, -0.0572,  0.2688,  ..., -0.0290, -0.1406,  0.1829],
        [ 0.0216,  0.0566, -0.1793,  ..., -0.0414,  0.1633,  0.1022],
        ...,
        [-0.0707, -0.1225,  0.1844,  ...,  0.1269,  0.0030,  0.2382],
        [-0.0614, -0.0599,  0.0427,  ...,  0.1384,  0.0629,  0.0175],
        [ 0.1224,  0.1871,  0.2072,  ...,  0.0039, -0.2088,  0.0193]],
       device='cuda:0', requires_grad=True)
predict_reward.0.bias Parameter containing:
tensor([-0.0243,  0.1298, -0.2345,  0.0297,  0.0570,  0.1353,  0.0357, -0.1581,
        -0.2047, -0.1751, -0.1258, -0.1492,  0.1966, -0.1401, -0.1424,  0.1452,
        -0.0428, -0.0265, -0.0751, -0.0207,  0.0214, -0.0541,  0.0376,  0.1757,
        -0.0749,  0.0301,  0.1644, -0.1580, -0.1230,  0.1029,  0.1647, -0.1095,
        -0.0192,  0.0228,  0.1501,  0.1570,  0.2532,  0.1129,  0.1276, -0.0833,
         0.2083, -0.0446,  0.1626,  0.0400,  0.1954, -0.1349, -0.1300,  0.1975,
         0.1167, -0.2050, -0.0386, -0.0319, -0.1121,  0.2069, -0.0708,  0.0703,
        -0.0271,  0.1207, -0.0662, -0.1261,  0.0769,  0.2092,  0.0101,  0.2022],
       device='cuda:0', requires_grad=True)
predict_reward.2.weight Parameter containing:
tensor([[-0.0196, -0.0201, -0.0833,  ..., -0.0046,  0.0999,  0.1278],
        [ 0.0621,  0.0359, -0.0693,  ...,  0.0871, -0.0040,  0.1342],
        [ 0.0430,  0.2113, -0.0692,  ..., -0.0546,  0.1193,  0.0313],
        ...,
        [ 0.0950,  0.1131,  0.0360,  ...,  0.1526,  0.0937,  0.1593],
        [-0.0745,  0.0411, -0.0865,  ...,  0.0865,  0.0299,  0.1118],
        [-0.0355,  0.1539, -0.1625,  ..., -0.0294,  0.0842,  0.0258]],
       device='cuda:0', requires_grad=True)
predict_reward.2.bias Parameter containing:
tensor([ 0.0529,  0.1288,  0.0907,  0.0858, -0.0691,  0.1107,  0.1180,  0.1497,
        -0.1218,  0.1258, -0.0650,  0.0416,  0.0093, -0.1418,  0.0235,  0.0183,
        -0.0764, -0.1308, -0.0635, -0.1132, -0.1203,  0.0256,  0.0779, -0.1442,
        -0.1574, -0.0380, -0.0510,  0.0146, -0.0367, -0.0371,  0.1428, -0.0833,
         0.0907,  0.0025,  0.0415,  0.1210,  0.0609, -0.0520, -0.0278,  0.0353,
        -0.1072,  0.0677,  0.1448,  0.0290, -0.0585, -0.0590,  0.0226,  0.0072,
         0.0860,  0.0354, -0.0466,  0.1549, -0.0086, -0.0450,  0.1599,  0.0224,
        -0.0691,  0.1513, -0.0597, -0.0217, -0.0598, -0.0709,  0.1173,  0.0717],
       device='cuda:0', requires_grad=True)
predict_reward.4.weight Parameter containing:
tensor([[-0.0739, -0.2671, -0.3178,  0.1363, -0.1872, -0.1357, -0.2567, -0.1863,
          0.1727, -0.2853,  0.2359, -0.2859,  0.1870,  0.2436,  0.1758, -0.2629,
          0.3553,  0.2443,  0.1531,  0.2070,  0.3603,  0.2914, -0.1686,  0.2786,
          0.2128,  0.1767,  0.2672,  0.1767, -0.1818, -0.1285, -0.1955,  0.2347,
         -0.1731,  0.2369,  0.2888, -0.2691, -0.0323,  0.1945, -0.0090,  0.3035,
          0.2468,  0.2201, -0.2040, -0.3645,  0.3076, -0.3892, -0.2983,  0.3425,
         -0.2667,  0.1622, -0.2891, -0.1982, -0.3726,  0.0451, -0.2737,  0.1253,
         -0.1294, -0.0991,  0.1598,  0.2450, -0.1782, -0.2423, -0.2327, -0.2463]],
       device='cuda:0', requires_grad=True)
predict_reward.4.bias Parameter containing:
tensor([-0.0963], device='cuda:0', requires_grad=True)
mean: -87.570300046937 std 81.00314821723269
