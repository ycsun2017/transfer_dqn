episode: 0, total reward: -214.798
episode: 10, total reward: -60.948
episode: 20, total reward: -174.622
episode: 30, total reward: -98.042
episode: 40, total reward: -365.289
episode: 50, total reward: -131.987
episode: 60, total reward: -281.067
episode: 70, total reward: -159.624
episode: 80, total reward: -211.648
episode: 90, total reward: -63.573
episode: 100, total reward: -281.734
episode: 110, total reward: -188.985
episode: 120, total reward: -350.629
episode: 130, total reward: -45.406
episode: 140, total reward: -172.346
episode: 150, total reward: -117.029
episode: 160, total reward: -104.286
episode: 170, total reward: -184.535
episode: 180, total reward: -308.877
episode: 190, total reward: -260.771
episode: 200, total reward: -304.702
episode: 210, total reward: -81.036
episode: 220, total reward: -113.457
episode: 230, total reward: -110.383
episode: 240, total reward: -161.79
episode: 250, total reward: -245.18
episode: 260, total reward: -94.378
episode: 270, total reward: 30.969
episode: 280, total reward: -91.217
episode: 290, total reward: -89.811
episode: 300, total reward: -89.114
episode: 310, total reward: -115.434
episode: 320, total reward: -113.357
episode: 330, total reward: -82.549
episode: 340, total reward: -211.037
episode: 350, total reward: -197.768
episode: 360, total reward: -136.99
episode: 370, total reward: -109.755
episode: 380, total reward: -210.844
episode: 390, total reward: -90.56
episode: 400, total reward: -184.056
episode: 410, total reward: -115.465
episode: 420, total reward: -84.12
episode: 430, total reward: -104.806
episode: 440, total reward: -88.362
episode: 450, total reward: -73.325
episode: 460, total reward: -115.307
episode: 470, total reward: -111.924
episode: 480, total reward: -372.887
episode: 490, total reward: -107.407
episode: 500, total reward: -106.38
episode: 510, total reward: -162.662
episode: 520, total reward: -152.2
episode: 530, total reward: -74.928
episode: 540, total reward: -150.127
episode: 550, total reward: -135.189
episode: 560, total reward: -69.38
episode: 570, total reward: -121.378
episode: 580, total reward: -279.929
episode: 590, total reward: -125.529
episode: 600, total reward: -152.427
episode: 610, total reward: -91.471
episode: 620, total reward: -73.334
episode: 630, total reward: -58.442
episode: 640, total reward: -102.586
episode: 650, total reward: -110.183
episode: 660, total reward: 33.872
episode: 670, total reward: -91.518
episode: 680, total reward: -186.208
episode: 690, total reward: -117.531
episode: 700, total reward: -114.571
episode: 710, total reward: -55.419
episode: 720, total reward: -90.388
episode: 730, total reward: -43.801
episode: 740, total reward: -40.144
episode: 750, total reward: -124.625
episode: 760, total reward: -274.772
episode: 770, total reward: -39.424
episode: 780, total reward: -85.917
episode: 790, total reward: -136.602
episode: 800, total reward: -36.977
episode: 810, total reward: -32.865
episode: 820, total reward: -67.494
episode: 830, total reward: -283.286
episode: 840, total reward: -271.698
episode: 850, total reward: -73.192
episode: 860, total reward: -61.025
episode: 870, total reward: -103.16
episode: 890, total reward: -108.47
episode: 900, total reward: -60.093
episode: 910, total reward: -3.27
episode: 920, total reward: -60.556
episode: 940, total reward: 25.85
episode: 950, total reward: 47.314
episode: 960, total reward: 0.239
episode: 980, total reward: 45.851
episode: 990, total reward: -7.852
episode: 1020, total reward: -34.701
episode: 1050, total reward: 43.981
episode: 1080, total reward: -41.998
episode: 1090, total reward: 13.235
episode: 1100, total reward: 15.809
episode: 1120, total reward: 3.01
episode: 1190, total reward: -84.147
episode: 1210, total reward: 58.209
episode: 1300, total reward: 10.514
episode: 1340, total reward: -15.474
episode: 1350, total reward: 17.654
episode: 1440, total reward: -147.13
episode: 1450, total reward: -8.073
episode: 1470, total reward: -96.906
episode: 1570, total reward: 42.516
episode: 1660, total reward: -87.668
episode: 1670, total reward: 2.702
episode: 1680, total reward: -107.483
episode: 1690, total reward: -97.162
episode: 1700, total reward: -186.313
episode: 1710, total reward: -142.557
episode: 1830, total reward: 12.902
episode: 1850, total reward: 26.113
episode: 1870, total reward: 32.172
episode: 1880, total reward: 39.074
episode: 1890, total reward: -2.714
episode: 1900, total reward: 24.516
episode: 1910, total reward: -9.35
episode: 2570, total reward: -57.987
episode: 2580, total reward: -59.032
episode: 2590, total reward: 51.048
episode: 2670, total reward: -8.985
episode: 2720, total reward: 2.61
episode: 2740, total reward: 6.895
episode: 2760, total reward: -14.41
episode: 2780, total reward: 14.732
episode: 2870, total reward: 39.113
episode: 2890, total reward: 8.122
episode: 2910, total reward: -222.008
episode: 2930, total reward: -8.372
episode: 2960, total reward: -11.615
episode: 2970, total reward: 39.275
predict_state.0.weight Parameter containing:
tensor([[ 0.0837,  0.0339, -0.0659,  ...,  0.0683,  0.1620, -0.0221],
        [-0.0940,  0.0856, -0.2786,  ...,  0.1549, -0.0024, -0.3960],
        [-0.0445,  0.1011,  0.2671,  ..., -0.0385,  0.1122,  0.1106],
        ...,
        [-0.0106, -0.1861, -0.0213,  ...,  0.2195, -0.1543, -0.0818],
        [ 0.1936,  0.1664, -0.1136,  ..., -0.1282,  0.0357,  0.0061],
        [-0.0975,  0.1764,  0.1055,  ...,  0.0177,  0.0289, -0.0619]],
       requires_grad=True)
predict_state.0.bias Parameter containing:
tensor([ 0.0080, -0.2957, -0.1609,  0.1552, -0.1897, -0.0232,  0.0671, -0.0175,
        -0.1579, -0.0719,  0.0272,  0.0590,  0.0328, -0.1598,  0.0366, -0.1148,
        -0.0537,  0.0443,  0.0529,  0.1070,  0.0954, -0.0979,  0.1759,  0.1475,
        -0.1139, -0.0071,  0.1481,  0.1530, -0.2237, -0.0635,  0.0611,  0.1564,
         0.1345,  0.0696, -0.0014,  0.0414,  0.0393,  0.2462,  0.0164, -0.1652,
         0.0396,  0.1435,  0.0426,  0.0044, -0.0433, -0.0953, -0.0633,  0.1355,
        -0.1948,  0.0289, -0.0542,  0.0952,  0.0264,  0.1794,  0.1870,  0.0412,
         0.1684,  0.1332,  0.1238,  0.0480,  0.0951,  0.2108, -0.1949,  0.0030],
       requires_grad=True)
predict_state.2.weight Parameter containing:
tensor([[ 0.1210, -0.1961,  0.0561,  ...,  0.0607,  0.2567,  0.1383],
        [ 0.0703,  0.0700,  0.0982,  ...,  0.0273, -0.0146,  0.2100],
        [ 0.0692, -0.0927, -0.0713,  ...,  0.0430, -0.0065, -0.0246],
        ...,
        [ 0.1496,  0.1798,  0.0996,  ..., -0.0144, -0.1990,  0.0338],
        [-0.1007,  0.1950, -0.0413,  ..., -0.0212,  0.0543,  0.0266],
        [-0.0443, -0.1351, -0.0214,  ...,  0.0945,  0.0438,  0.1047]],
       requires_grad=True)
predict_state.2.bias Parameter containing:
tensor([-0.0731, -0.1294,  0.1091, -0.0933, -0.0805, -0.0362,  0.0378, -0.0416,
        -0.0193,  0.0667,  0.0918,  0.0845, -0.0326, -0.0244, -0.0579,  0.0286,
         0.0660,  0.0367,  0.0798,  0.0102,  0.0694,  0.0027,  0.0977,  0.0599,
         0.1088,  0.0224, -0.0899, -0.0234,  0.0851, -0.0846,  0.1091, -0.0855,
        -0.0087,  0.0478, -0.0690,  0.0265,  0.0538,  0.1071,  0.0258,  0.0350,
        -0.0233,  0.0642,  0.0537,  0.0853, -0.0016, -0.0673, -0.0792,  0.0742,
        -0.0702, -0.1128,  0.1223,  0.0612,  0.1097,  0.0036, -0.0186, -0.0876,
         0.0399,  0.0526,  0.0393,  0.1056, -0.0854,  0.1111,  0.0933,  0.0871],
       requires_grad=True)
predict_state.4.weight Parameter containing:
tensor([[-0.1889, -0.0202,  0.0294,  ...,  0.0255,  0.2579,  0.0122],
        [-0.0565,  0.1405, -0.0317,  ...,  0.2462,  0.0493, -0.3043],
        [-0.0331,  0.1362,  0.0048,  ...,  0.1694,  0.2933, -0.0749],
        ...,
        [ 0.2596, -0.0013, -0.1132,  ..., -0.1064, -0.1021, -0.0494],
        [-0.2916,  0.1106,  0.0284,  ...,  0.2876,  0.1615, -0.2775],
        [ 0.2552, -0.1577,  0.0930,  ..., -0.0285, -0.2922, -0.0356]],
       requires_grad=True)
predict_state.4.bias Parameter containing:
tensor([ 0.0509, -0.0365,  0.1051,  0.0231, -0.1117,  0.1001,  0.0169,  0.0567,
        -0.0615, -0.0309,  0.1045,  0.0738, -0.0267,  0.0085,  0.0594, -0.0988],
       requires_grad=True)
predict_reward.0.weight Parameter containing:
tensor([[ 0.0981,  0.0904,  0.1695,  ...,  0.0397,  0.0653,  0.0296],
        [ 0.3399, -0.0572,  0.2688,  ..., -0.0290, -0.1406,  0.1829],
        [ 0.0216,  0.0566, -0.1793,  ..., -0.0414,  0.1633,  0.1022],
        ...,
        [-0.0707, -0.1225,  0.1844,  ...,  0.1269,  0.0030,  0.2382],
        [-0.0614, -0.0599,  0.0427,  ...,  0.1384,  0.0629,  0.0175],
        [ 0.1224,  0.1871,  0.2072,  ...,  0.0039, -0.2088,  0.0193]],
       requires_grad=True)
predict_reward.0.bias Parameter containing:
tensor([-0.0243,  0.1298, -0.2345,  0.0297,  0.0570,  0.1353,  0.0357, -0.1581,
        -0.2047, -0.1751, -0.1258, -0.1492,  0.1966, -0.1401, -0.1424,  0.1452,
        -0.0428, -0.0265, -0.0751, -0.0207,  0.0214, -0.0541,  0.0376,  0.1757,
        -0.0749,  0.0301,  0.1644, -0.1580, -0.1230,  0.1029,  0.1647, -0.1095,
        -0.0192,  0.0228,  0.1501,  0.1570,  0.2532,  0.1129,  0.1276, -0.0833,
         0.2083, -0.0446,  0.1626,  0.0400,  0.1954, -0.1349, -0.1300,  0.1975,
         0.1167, -0.2050, -0.0386, -0.0319, -0.1121,  0.2069, -0.0708,  0.0703,
        -0.0271,  0.1207, -0.0662, -0.1261,  0.0769,  0.2092,  0.0101,  0.2022],
       requires_grad=True)
predict_reward.2.weight Parameter containing:
tensor([[-0.0196, -0.0201, -0.0833,  ..., -0.0046,  0.0999,  0.1278],
        [ 0.0621,  0.0359, -0.0693,  ...,  0.0871, -0.0040,  0.1342],
        [ 0.0430,  0.2113, -0.0692,  ..., -0.0546,  0.1193,  0.0313],
        ...,
        [ 0.0950,  0.1131,  0.0360,  ...,  0.1526,  0.0937,  0.1593],
        [-0.0745,  0.0411, -0.0865,  ...,  0.0865,  0.0299,  0.1118],
        [-0.0355,  0.1539, -0.1625,  ..., -0.0294,  0.0842,  0.0258]],
       requires_grad=True)
predict_reward.2.bias Parameter containing:
tensor([ 0.0529,  0.1288,  0.0907,  0.0858, -0.0691,  0.1107,  0.1180,  0.1497,
        -0.1218,  0.1258, -0.0650,  0.0416,  0.0093, -0.1418,  0.0235,  0.0183,
        -0.0764, -0.1308, -0.0635, -0.1132, -0.1203,  0.0256,  0.0779, -0.1442,
        -0.1574, -0.0380, -0.0510,  0.0146, -0.0367, -0.0371,  0.1428, -0.0833,
         0.0907,  0.0025,  0.0415,  0.1210,  0.0609, -0.0520, -0.0278,  0.0353,
        -0.1072,  0.0677,  0.1448,  0.0290, -0.0585, -0.0590,  0.0226,  0.0072,
         0.0860,  0.0354, -0.0466,  0.1549, -0.0086, -0.0450,  0.1599,  0.0224,
        -0.0691,  0.1513, -0.0597, -0.0217, -0.0598, -0.0709,  0.1173,  0.0717],
       requires_grad=True)
predict_reward.4.weight Parameter containing:
tensor([[-0.0739, -0.2671, -0.3178,  0.1363, -0.1872, -0.1357, -0.2567, -0.1863,
          0.1727, -0.2853,  0.2359, -0.2859,  0.1870,  0.2436,  0.1758, -0.2629,
          0.3553,  0.2443,  0.1531,  0.2070,  0.3603,  0.2914, -0.1686,  0.2786,
          0.2128,  0.1767,  0.2672,  0.1767, -0.1818, -0.1285, -0.1955,  0.2347,
         -0.1731,  0.2369,  0.2888, -0.2691, -0.0323,  0.1945, -0.0090,  0.3035,
          0.2468,  0.2201, -0.2040, -0.3645,  0.3076, -0.3892, -0.2983,  0.3425,
         -0.2667,  0.1622, -0.2891, -0.1982, -0.3726,  0.0451, -0.2737,  0.1253,
         -0.1294, -0.0991,  0.1598,  0.2450, -0.1782, -0.2423, -0.2327, -0.2463]],
       requires_grad=True)
predict_reward.4.bias Parameter containing:
tensor([-0.0963], requires_grad=True)
mean: -91.95712225639261 std 98.13802685971274
